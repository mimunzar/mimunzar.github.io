<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <link rel="stylesheet" type="text/css" href="../index.css">
  <title>Linear Regression</title>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

  <a href="../index.html">&lt;&lt; back</a>
  <h2>Linear Regression</h2>

  <p>Let's have some data from which we can make predictions by approximating
  them with a linear function. We can describe the data by having values
  generated by a function with added random noise. The noise can have a normal
  distribution with zero mean.</p>

  $$\begin{aligned}
    y &= f(x) + noise \\
      &= f(x) + \mathcal{N}(0, \sigma) \\
      &= \mathcal{N}(f(x), \sigma)
  \end{aligned}$$

  <p>To predict new values  we  can  draw  from  the  above  distribution.   The
  distribution is described by a conditional probability (probability of  output
  values given input).</p>

  $$\begin{aligned}
    p(y|x)
      &= \mathcal{N}(f(x), \sigma) \\
      &= {1 \over \sqrt{2\pi\sigma^2}}\exp(-{(y - f(x))^2 \over 2\sigma^2})
  \end{aligned}
  \tag{1}\label{eq:foo}$$

  <p>To make meaningful predictions we need to  adjust  this  distribution.   It
  should maximize the conditional likelihood of the training data \(X  =  ((x_1,
  y_1)  \dots  (x_l,  y_l))\).   We  do  it  by  estimating  parameters  of  the
  distribution \(W\).</p>

  $$\begin{aligned}
    W_{MCLE} 
      &= \arg\max_W \prod_l p(y^l|x^l, W) \\
      &= \arg\max_W \sum_l \ln p(y^l|x^l, W) \\
      &= \arg\max_W \lambda(W)
  \end{aligned}$$

  <p>The parameters should maximize our  reward  function  \(\lambda(W)\).   The
  function assigns reward to predictions with respect to current parameters.  It
  assigns high  reward  to  close  predictions  and  low  rewards  to  far  away
  predictions.</p>

  $$\begin{aligned}
    \lambda(W)
      &= \sum_l \ln {1 \over \sqrt{2\pi\sigma^2}}\exp(-{(y^l - f(x^l, W))^2 \over 2\sigma^2}) \\
      &= \sum_l \ln {1 \over \sqrt{2\pi\sigma^2}} + \ln \exp(-{(y^l - f(x^l, W))^2 \over 2\sigma^2}) \\
      &= \sum_l \ln {1 \over \sqrt{2\pi\sigma^2}} - {(y^l - f(x^l, W))^2 \over 2\sigma^2} \\
      &= \sum_l A - B
  \end{aligned}$$

  <p>To find the parameters which  maximize  our  reward  function  we  can  use
  Gradient Ascent algorithm.  The algorithm repeatedly computes  gradient  of  a
  reward function from the training data and updates parameters in  a  direction
  of the gradient.</p>

  <p>The gradient is computed by taking a  derivative  of  the  reward  function
  with respect to each parameter.  The derivative  of  the  \(A\)  term  is:</p>

  $$\begin{aligned}
    {\partial A \over \partial w_i}
      &= {\partial \ln {1 \over \sqrt{2\pi\sigma^2}} \over \partial w_i} \\
      &= 0
  \end{aligned}$$

  <p>And the derivation of the \(B\) term is:</p>

  $$\begin{aligned}
    {\partial B \over \partial w_i} 
      &= {\partial {(y^l - f(x^l, W))^2 \over 2\sigma^2} \over \partial w_i} \\
      &=  {1 \over 2\sigma^2} 2(y^l - f(x^l, W)) (-{\partial f(x^l, W) \over \partial w_i}) \\
      &= -{(y^l - f(x^l, W)) \over \sigma^2}{\partial f(x^l, W) \over \partial w_i}
  \end{aligned}$$

  <p>This follows from the application of the Chain Rule:</p>

  $$\begin{aligned}
    {\partial {(y^l - f(x^l, W))^2 \over 2\sigma^2} \over \partial (y^l - f(x^l, W))^2}
      &= {1 \over 2\sigma^2} \\[10pt]
    {\partial (y^l - f(x^l, W))^2 \over \partial (y^l - f(x^l, W))}
      &= 2(y^l - f(x^l, W)) \\[10pt]
    {\partial (y^l - f(x^l, W)) \over \partial f(x^l, W)}
      &= -{\partial f(x^l, W) \over \partial w_i}
  \end{aligned}$$

  <p>The final equation computes gradient for our reward function:</p>

  $$\begin{aligned}
    {\partial \lambda(W) \over \partial w_i}
      &= \sum_l {\partial A \over \partial w_i} - {\partial B \over \partial w_i} \\
      &= \sum_l {(y^l - f(x^l, W)) \over \sigma^2}{\partial f(x^l, W) \over \partial w_i}
  \end{aligned}$$

  <p>Which we can use to update the parameters (with learning rate \(\eta\))  of
  the distribution:</p>

  $$\begin{aligned}
    w_i(t + 1)
      &= w_i(t) + \eta{\partial \lambda(W) \over \partial w_i} \\
      &= w_i(t) + \eta{\sum_l {(y^l - f(x^l, W)) \over \sigma^2}{\partial f(x^l, W) \over \partial w_i}}
  \end{aligned}$$

  <h3>Alternative: Sum of Square Loss</h3>

  <p>Simpler alternative is to notice that in  \eqref{eq:foo}  the  only  moving
  part is the numerator in the exponent.  The numerator maximizes  the  equation
  when it is zero (rewards correct prediction).  Thus  it  is  the  same  as  to
  minimize the sum of squared errors.</p>

  $$\begin{aligned}
    W_{MCLE}
      &= \arg\min_W \sum_l (y - f(x, W))^2 \\
      &= \arg\min_W \lambda(W)
  \end{aligned}$$

  <p>The \(\lambda(W)\) function assigns small losses to close  predictions  and
  big losses to far away predictions.  To find the parameters which minimize our
  loss function we can use Gradient  Descent  algorithm.   The  algorithm  is  a
  parallel to Gradient Ascent algorithm.  We start by  computing  gradients.</p>

  $$
    {\partial \lambda(W) \over \partial w_i} = \sum_l -2(y - f(x, W)){\partial f(x, W) \over \partial w_i}
  $$

  <p>This follows from the application of the Chain Rule:</p>

  $$\begin{aligned}
    {\partial (y - f(x, W))^2 \over \partial (y - f(x, W))}
      &= 2(y - f(x, W)) \\[10pt]
    {\partial (y - f(x, W)) \over \partial w_i}
      &= -{\partial f(x, W) \over \partial w_i}
  \end{aligned}$$

  <p>The update  of  parameters  is  now  done  in  opposite  direction  of  the
  gradient.</p>

  $$\begin{aligned}
    w_i(t + 1)
      &= w_i(t) - \eta{\partial \lambda(W) \over \partial w_i} \\
      &= w_i(t) - \eta{\sum_l -2(y - f(x, W)){\partial f(x, W) \over \partial w_i}}
  \end{aligned}$$

  <h3>References</h3>

  <dl>
    <dt>Tom Mitchell: Carnegie Mellon University</dt>
    <dd><a href="http://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml">http://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml</a></dd>
  </dl>

</body>
</html>

